{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2 \n",
    "import PIL.Image as Image\n",
    "import torch\n",
    "import torchvision\n",
    "# from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as T\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = \"cpu\" \n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 224\n",
    "transforms = T.Compose(\n",
    "            [T.Resize((IMAGE_SIZE,IMAGE_SIZE)),\n",
    "            # T.ToTensor(),\n",
    "            # T.Normalize([0.5,0.5,0.5],[0.25,0.25,0.25]),            \n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using albumentations\n",
    "# import albumentations as A\n",
    "# from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# transforms_album =   A.Compose([\n",
    "#     A.Resize(128,128),\n",
    "#     A.HorizontalFlip(p=0.38),\n",
    "#     A.Normalize([0.5,0.5,0.5],[0.25,0.25,0.25]),\n",
    "#     ToTensorV2()\n",
    "#     ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogCatDataset(Dataset):\n",
    "  def __init__ (self, annotations_file, img_dir, transform=transforms,target_transform=None):\n",
    "    self.img_labels = pd.read_csv(annotations_file, sep=(','))\n",
    "    self.img_dir = img_dir\n",
    "    self.transform = transform\n",
    "    self.target_transform = target_transform\n",
    "  def __len__(self):\n",
    "    return len(self.img_labels)\n",
    "  def __getitem__(self, index):\n",
    "    img_path = os.path.join(self.img_dir, self.img_labels.iloc[index,0])\n",
    "    image = cv2.imread(img_path)\n",
    "    label = self.img_labels.iloc[index,1]\n",
    "    \n",
    "    if self.transform == transforms:\n",
    "            image = self.transform(image)\n",
    "    # elif self.transform == transforms_album:\n",
    "    #     augmented = self.transform(image=image)\n",
    "    #     image = augmented['image']\n",
    "    return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1950 750 300\n"
     ]
    }
   ],
   "source": [
    "images='/home/sandbox-2/Documents/Gopal_office_file/dogs-vs-cats/dataset_3000img'\n",
    "label=\"/home/sandbox-2/Documents/Gopal_office_file/dogs-vs-cats/dataset3000.csv\"\n",
    "\n",
    "dataset = DogCatDataset(annotations_file=label,img_dir=images)\n",
    "\n",
    "train_per = int(len(dataset)*0.65)\n",
    "val_per = int(len(dataset)*0.25)\n",
    "test_per = len(dataset)-train_per-val_per\n",
    "\n",
    "train_data, validation_data, test_data= torch.utils.data.random_split(dataset,[train_per,val_per,test_per])    #16250,3750,5000\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data,batch_size=batch_size,shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_data,batch_size=batch_size,shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_data,batch_size=batch_size,shuffle=False)\n",
    "\n",
    "print(train_per, val_per, test_per)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenth of Train data ----->1950         \n",
      "Lenth of Validation data ----->750       # \n",
      "Lenth of Test data ----->300\n"
     ]
    }
   ],
   "source": [
    "print(f\"Lenth of Train data ----->{len(train_data)} \\\n",
    "        \\nLenth of Validation data ----->{len(validation_data)}\\\n",
    "       # \\nLenth of Test data ----->{len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = train_data[0][1]\n",
    "# img = train_data[0]\n",
    "# print(img)\n",
    "# img = T.ToPILImage()(img).convert(\"RGB\")\n",
    "# img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(3,48,3,stride=2,padding=1),nn.ReLU(),\n",
    "    nn.MaxPool2d(3,3),\n",
    "\n",
    "    nn.Conv2d(48,96,kernel_size=3,padding=2), nn.ReLU(),\n",
    "    nn.MaxPool2d(3,2),\n",
    "\n",
    " # nn.Conv2d(256,384,3,1), nn.ReLU(),\n",
    "    nn.Conv2d(96,96,3,1), nn.ReLU(),\n",
    "    nn.MaxPool2d(3,2),\n",
    "    nn.Conv2d(96,192,3,1), nn.ReLU(),\n",
    "    nn.MaxPool2d(3,2),\n",
    "    \n",
    "    nn.Flatten(),\n",
    "\n",
    "    nn.Linear(768,384),nn.ReLU(),\n",
    "    nn.Dropout(p=0.7),\n",
    "    nn.Linear(384,192),nn.ReLU(),\n",
    "    nn.Dropout(p=0.7),\n",
    "    nn.Linear(192,2)  \n",
    ")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0000001)\n",
    "epoch = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "valiadtion_loss = []\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "epoch = epoch\n",
    "\n",
    "best_loss = np.inf\n",
    "early_stopping_iter = 10\n",
    "early_stopping_counter = 10\n",
    "\n",
    "for t in range(epoch):\n",
    "    start = time()\n",
    "    print(f\"Epoch {t+1}\\n .........................\")\n",
    "    \n",
    "    for data_loader in [train_loader,validation_loader]:\n",
    "        if data_loader == train_loader:\n",
    "            model.train()\n",
    "        else:\n",
    "            model.eval()\n",
    "        losses=[]\n",
    "        size = len(data_loader.dataset)\n",
    "        for batch, (X,y) in enumerate(data_loader):                 \n",
    "            #computr prediction and loss\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred,y)\n",
    "            losses.append(loss.item())\n",
    "            if data_loader == train_loader:\n",
    "            #Backprobagation\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        if data_loader == train_loader:\n",
    "            train_loss.append(np.mean(losses))\n",
    "        if data_loader == validation_loader:\n",
    "            valiadtion_loss.append(np.mean(losses))\n",
    "            if valiadtion_loss < best_loss:\n",
    "                best_loss = valiadtion_loss\n",
    "            else:\n",
    "                early_stopping_counter += 1\n",
    "\n",
    "    for data_loader in [train_loader,test_loader]:\n",
    "        model.eval()          \n",
    "        correct=0.0\n",
    "        total=0.0\n",
    "        size = len(data_loader.dataset)\n",
    "        for batch, (X,y) in enumerate(data_loader):\n",
    "            X, y = X, y           \n",
    "            #computr prediction and loss\n",
    "            pred = model(X)\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            \n",
    "      \n",
    "        if data_loader == test_loader:\n",
    "            test_acc=correct/size*100\n",
    "            test_accuracy.append(test_acc)\n",
    "        if data_loader == train_loader:\n",
    "            train_acc=correct/size*100\n",
    "            train_accuracy.append(train_acc)\n",
    "    print((time()-start)/60,\"mins\")\n",
    "\n",
    "    if early_stopping_counter > early_stopping_iter:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(epoch),train_loss,label='Train Loss')\n",
    "# plt.plot(np.arange(epoch),valiadtion_loss,label='Valiadtion Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Losses')\n",
    "plt.title(\"Losses Plot\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(epoch),train_accuracy,label='Train Accuracy')\n",
    "plt.plot(np.arange(epoch),test_accuracy,label='Test Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Accuracy Plot\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test with the saved weights\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    npimg = np.transpose(npimg, (1, 2, 0))\n",
    "    npimg = npimg[...,::-1]\n",
    "    plt.imshow(npimg)\n",
    "    plt.show()\n",
    "classes = ('cat','dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/sandbox-2/Documents/Gopal_office_file/dogs-vs-cats/model.pth'\n",
    "dataiter = iter(train_loader)\n",
    "image,label = dataiter.next()\n",
    "\n",
    "print(image.shape)\n",
    "\n",
    "#print images\n",
    "# imshow(torchvision.utils.make_grid(image))\n",
    "# print(' '.join(f'{classes[label[j]]:5s}' for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(path,map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(image)\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}'\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 89 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = model(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class: cat   is 89.2 %\n",
      "Accuracy for class: dog   is 85.3 %\n"
     ]
    }
   ],
   "source": [
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generic function to display predictions for a few images\n",
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(test_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title(f'predicted: {classes[preds[j]]}, original{classes[labels[j]]}')\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(model)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "81ecab893dd4a35f3f9bb099b8f1434b87b41985c6b58dc70d26b2c1f3b85889"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('dl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
